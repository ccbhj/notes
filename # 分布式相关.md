# 分布式相关

1. 一致性:

   强一致性: 数据更新成功后, 任意时刻所有副本都是一致的, 一般为同步实现

   弱一致性: 数据更新成功后, 系统不承诺什么时候可以在任何副本上读到最新值

   最终一致性: 弱一致性的一种, 系统不承诺可以立即读到最新值, 但保证最终每个副本都会有最新值

2. ## 分布式事务:

   1. 两段式提交(XA) --  **强一致性**:  利用**事务管理器**来协调各个数据库(资源),

      - 表决: 提交事务前先询问各个数据库是否可以执行提交操作, 参与者执行事务操作, 写入undo, redo log, 然后回复ok,

      - 询问: 协调者询问参与者, 如果都回复ok, 那么正式提交事务, 在所有数据库进行commit,  若有一个不ok, 则进行回滚

      - 优缺点: 
        - 实现简单.  
        - 同步阻塞, 数据库应答前, 事务管理器都得阻塞
        - 单点问题:事务管理器单点, 一旦事务管理器一出现问题, 所有数据库都会被锁定
        - 数据不一致: 数据库在第二阶段出现故障, 导致数据不一致
        - 容错性低: 任何一个数据库出现问题, 都会导致事务失败, 对于有副本的数据库来说, 其实没必要直接rollback
      
   2. 三段式提交(cancommit, precommit, docommit) --  **强一致性**:
      
      事务协调者和参与者都要超时 
      
      - cancommit: 先询问各个数据库是否可以执行事务, 然后等待响应. 
      - precommit: 执行各个事务操作, 即将事务操作写入undo, redo log, 并返回ok
      - docommit: 通知所有事务进行commit, 若任何一个操作出现问题, 则需要进行补偿回滚, 即执行已完成事务的
      
   3. ebay事件队列方案(本地消息表) -- **最终一致性**:

      核心思想是将需要分布式处理的任务通过消息或者日志的方式来异步执行，消息或日志可以存到本地文件、数据库或消息队列，再通过业务规则进行失败重试，它要求各服务的接口是幂等的。

      - 消息产生方建立一个消息表记录消息发送状态, 消息表和业务数据要在一个事务里提交, 然后消息(prepare)通过mq发送到消费方, 如果消息发送失败, 则进行重试
      - 消息消费方收到消息后处理自己的事务, 如果自己的事务执行失败, 则进行重试, 如果业务层面失败了, 则发送一个补偿机制让生产方回滚(同时删除通知者的发送消息)
      - 生产方和消费方都要定时扫描本地消息表, 把没处理的消息处理一遍或重新发送, **一定要保持可靠消息的传递**

   4. TCC(**try confirm cancel**) -- 强一致性:

      1.  try: 对各个资源进行检测, 锁定, 预留. 并告知事务管理器是否ok, ok则confirm, 失败则cancel
      2. confirm: 执行各个事务操作, 这个阶段默认不会出错(因为在try阶段已经执行资源检查了)
      3. cancel: 当事务出错时, 需要释放try时预留的资源等, 即进行回滚  
      4. 优缺点:
         1. 需要自己去编写cancel时的操作, 业务侵入
         2. 强一致性,  涉及到钱的时候

   5. SAGA模式 -- **最终一致性, 用于长活事务**:

      1. 事件驱动模式: 每个事务参与者的本地既有正向业务流程也有一个补偿逆向事务, 当事务失败时, 则依次往前回退通知前一个事务参与者执行补偿逆向事务, 成功则通知下个事务参与者执行事务
      2. 优缺点:
         1. 一阶段提交本地事务, 无锁, 高性能
         2. 事件驱动, 异步执行, 高吞吐
         3. 用于长事务
         4. 没有“预留“操作, 不能保证隔离性

3. ## 分布式锁:

   1. redis:

      1. setnx / set:

         - 加上超时, 避免故障, 无法解锁导致死锁

         - 官方推荐set, 因为setnx不支持直接设置超时, 需要用expire命令, 失去原子性
         - 当一个线程持有锁过久超过锁的超时时间, 那么之后的某个线程过来就会直接加锁, 但之后这个锁可能被刚才的线程解掉, 这时需要**给每个线程加的锁一个唯一性id, 避免删除别人的锁, 这是的get和set操作需要写在lua脚本, 或者事务**

      2. redlock(redis官方的分布式锁算法):

         1. 获取当前时间戳

         2. 轮流尝试在每个redis master节点上使用相同的键名和随机值来加锁, 加锁超时较短, 一般几十毫秒(为了防止网络出现问题, 或者某个节点挂re掉)

         3. client获取当前时间戳并减去第一步的时间并作为**获取锁的时间**,**这个时间要小于锁键的TTL才行**, 要在大多数节点上加锁, 超过(n/2 + 1)个节点枷锁成功, 才算成功. 

         4. 如果获得锁了, 则其有效时间必须减去获取锁的时间(第三步计算出的)

         5. 若获取锁失败, 则需要解锁所有实例

            **释放锁很简单, 删除全部实例上的锁就可以了**

            **当两个节点加锁了所有节点中各一半的节点(出现脑裂), 则需要在随机延迟后进行重试**

   2. zookeeper:

      加锁: 

      1. 在某个目录如/lock/下创建一个临时有序节点(防止死锁),
      2. 判断在当前目录下, 新节点的序号是否最小, 是则成功, 不是则在前一个节点添加一个删除事件(解锁)监听, 这样前一个节点解锁就能唤醒当前节点 , 这样是为了可以通知唤醒其他加锁线程.
   
3. 优缺点比较:
   
   redis优缺点: 
   
   - redis性能极高
   
      - 获取不到锁则需要不断尝试, 消耗性能
   - redis不是强一致性的(与其同步机制有关)
   
   zk分布锁
   
      - 强一致性, 适合做分布锁, 
      - 获取不到锁加监听器即可, 不用一直等待.
   
5. ### ZooKeeper:

   1. 如何保证一致性?

      **ZAB协议**: 有两种模式 -- **恢复模式(选举leader)和广播模式(主从同步)**, 当leader服务器故障或者启动时, 需要进行leader选举(类似raft). 之后进行状态同步使得leader和follower一致

   2. **zookeeper可以做服务注册中心**:

      zk的数据模型为树形结构, 在进行服务注册时, 会创建一个znode, 存储了服务的ip, 端口, 调用方式等等, 以供服务发现者读取, 当一个服务下线时, znode可以被删除(心跳机制), 同时zookeeper的监听机制使得发现者可在第一时间内被通知. 并且zk的zab也保证了高可用

   3. zk的读写机制:

      leader负责主机的读写

      follower负责读, 并将写操作转发给leader, 并且follower还可以参与leader选举投票

      observer只做备份, 不参与投票

   4. zk的节点为什么需要是奇数?

      为了避免出现**脑裂**:

      - 假死: 由于心跳超时(网络原因)认为leader死了, 但其实还在

        脑裂: 由于假死引起新的leader选举, 选出一个新master, 但旧的master又通了, 导致两个master出现, 于是集群被分为2个小集群, 

        当集群数量为奇数时, 集群还是能选出leader(**因为要选出leader,必须保持可用节点>总节点/2**), 而当是偶数个时, 

      为了节省资源:

      对于3个节点, 要保持正常, 最少要有2个可用结点, 而对于4个节点, 则需要3个可用结点
