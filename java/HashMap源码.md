# HashMap源码

## HashMap

1. 长度相关:

   1. 最大长度: 2 ^ 30 次方

   2. 默认长度: 16 **就是一个经验值，定义16没有很特别的原因，只要是2次幂，其实用 8 和 32 都差不多 **

   3. threshold: 重散列阈值(等于capacity * load factor, 或默认最大长度)

   4. 默认负载因子阈值: 0.75  

   5. 红黑树化阈值: 8 (必须大于2且至少为8)

   6. 链表化阈值: 6

      **根据泊松分布，在负载因子默认为0.75的时候，单个hash槽内元素个数为8的概率小于百万分之一，所以将7作为一个分水岭，等于7的时候不转换，大于等于8的时候才进行转换，小于等于6的时候就化为链表 **

2. 哈希计算方式:

   **当键值为null时, 返回0, 不然返回键值的hashCode() ^ (h >>> 16).**

   **由于该表使用2的幂次掩码，因此16位以上的位会被忽略, 当hash值大于2 ^ 16 时, 会产生大量碰撞, 因此要先右移16位, 以让第16位以上的高位也影响hash, 用XOR的原因是其产生的1和0的概率是50% : 50%**

   

   数组索引为: index = (n - 1) & hash

   这样使得节点位置和桶数量相关, 同时n - 1 肯定为奇数, 1的个数更多, 使得哈希分散一些.

   

3. modCount

   哈系表被结构化修改次数, 结构化修改指的是那些映射次数被修改,或者其他内部结构的修改, 例如: 重散列.

   modCount用于制造迭代器, 用于fail-fast(防止迭代器失效). 在获取迭代器前迭代器存入modCount, 之后在每次next时都要检查modCount是否给修改.



1. put操作:

   - 若当前的表为空或者为初始化, 执行resize()
- 若新hash对应位置为null, 新建节点, 并返回null
   - 不然开始查找对于的桶(这里要区分树还是链表), 桶空就直接插入节点, 若新建后大于8需要红黑树化.

2. get操作:

   1. 对key的hashcode()结果进行hash()
   2. 如果对应的桶没有节点, 直接返回, 否则通过key.equals()去查找对应的entry(可能为树查找或者链表查找)

3. resize操作:

   1. cap大于0

   - 如果旧表的cap大于最大最大值, 旧表会被返回, 并且threshold会被设为无穷大, 防止重复resize.

   - 不然cap会被加倍, threshold也会加倍

   - 为什么要加倍: ** 扩容倍数为2，则tab长度一定为偶数，所以n-1位奇数，奇数的二进制形式最后一位一定是1，那么与hash进行与运算时得到的可能为奇数也可能为偶数，散列较为均匀。如果扩容倍数不为2，可能会出现tab长度为奇数的情况，当tab长度为奇数时，n-1一定为偶数，奇数的二进制形式最后一位一定是0，那么与hash进行与运算时得到的一定是偶数，会有一半的hash桶没有得到利用。**

   2. threshold大于0且cap小于等于0: cap和threshold设为默认值
   3. 申请新数组空间
   4. 遍历旧数组, 将整个桶复制到新数组, 保持原来的顺序



## ConcurrentHashMap(jdk8后)

- JDK1.7(注意): ConcurrentHashMap(jdk1.7以前):有一个名为Segment的内部final类，因此我们可以说ConcurrentHashMap在内部被划分为大小为32的段，因此最多32个线程可以一次工作。这意味着在高并发性期间，每个线程可以在每个段上工作，最多可以在32线程可以在max下运行，只需维护32个锁来保护ConcurrentHashMap的每个bucket。

1. 最大容量: 1 << 30
2. 默认容量: 16
3. 最大数组长度: Integer.MAX_VALUE - 8
4. 默认并发级别(Segment 长度): 16
5. 负载因子: 0.75
6. 树化阈值: 8
7. 链表化阈值: 6
8. 最小可树化数组容量(当小于这个值时, 不进行树化, 至少为4 * 树化阈值): 64 
9. 和普通HashMap一样, 负载因子为0.75时, 红黑树化阈值为8, 此概率少于一千万分之一
10. 两个线程访问不同线程的锁争用概率
    随机散列下的elements大约为1 /（8 * #elements）
11. **key 和value不能为null**

#### Node结构:

Node(节点类): 继承Map.Entry, 哈希值与键为final域, **val与next为volatile域(保证内存可见性)**

#### 初始化:
1. 哈希表懒初始化, 在第一次插入的时候才申请数组空间, 长度为2次幂
2. 只有空的表才能进行初始化
3. 当sizeCtl < 0时, 表示其他线程正在扩容或初始化, 开始自旋
4. 否则用CAS设置sizeCtl为-1, 即初始化状态,

#### PUT插入:
1. 判断键值是否为null, 若是要抛出NUllPointerException
2. 判断table(Node数组, volatile)里的每个项, 循环里:
    1. 表是否已初始化, 没有就需要初始化
    2. 桶是否为null, 没有直接用CAS写入, 不用加锁
    3. 如果正在扩容, 则协助进行扩容(调用helpTransfer)
    4. 桶头是否和要插入的键值一样(不用加锁)
    5. 如果以上都不行, 需要用synchronized加锁, 锁住表头
        1.对于链表(节点数小于8):  遍历, 若key已经存在则会进行覆盖, 不然就插入到表尾
        2.对于红黑树(节点树大于7), 旋转, 插入

    6. 最后判断是否需要扩容

#### 扩容:
1. 若新数组没有申请, 则申请为原来的2倍
2. 利用ForwardingNode[ 插入在桶头, 其hash值为MOVED, 并且指向新数组 ], 为正啊在迁移的节点
3. 只有新数组存在时才可以帮助扩容
4. 每个开始参与扩容的线程都要用CAS把sizeCtl加一, 完成后减一.
5. 查找范围
6. 开始扩容时, 找到lastRun节点, 将lastRun前后分成两个链表, lastRun及其之前的节点迁移到新数组位置, 之后的克隆到另外一个数组位置 
7. 最后在当前数组位置节点设置为当前的forwardingNode, 且设置其hash为Moved, 表示已经完成扩容-''


#### 获取节点(不加锁):
a、计算hash值，定位到该table索引位置，如果是首节点符合就返回
		b、如果遇到扩容的时候，会调用标志正在扩容节点ForwardingNode的find方法，查找该节点，匹配就返回
		c、以上都不符合的话，就往下遍历节点，匹配就返回，否则最后就返回null


